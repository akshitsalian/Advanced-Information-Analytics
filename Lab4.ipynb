{"cells":[{"cell_type":"markdown","source":["# Detecting happiness"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import functions as fn\nfrom pyspark.ml import classification, evaluation, Pipeline, feature\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%%sh\n# download and load dataset\nwget https://github.com/daniel-acuna/python_data_science_intro/raw/master/data/emotions.parquet.zip -nv\nunzip emotions.parquet.zip"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# read data\n# pixels: 48x48 pixel gray values (between 0 and 255) \nemotions = spark.read.parquet('file:///databricks/driver/emotions.parquet')"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# utility function to display the first element of a Spark dataframe as an image\ndef display_first_as_img(df):\n    plt.figure()\n    plt.imshow(df.first().pixels.reshape([48,48]), 'gray');\n    display()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# show random faces\ndisplay_first_as_img(emotions.where('is_happy=0').orderBy(fn.rand()))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# we will first balance the data so that we have 50% of faces is_happy = 1 and 50% faces is_happy = 0\nn_min = min(emotions.where('is_happy == 1').count(), emotions.where('is_happy == 0').count())\nbalanced_data = emotions.where('is_happy == 1').limit(n_min).\\\n  union(\n  emotions.where('is_happy == 0').limit(n_min)\n  )\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# check that it is balanced\ndisplay(balanced_data.groupBy('is_happy').count())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# use these splits throughout the homework\ntraining, validation, testing = balanced_data.randomSplit([0.6, 0.3, 0.1])"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["**Question 1 (40 pts):** Choose the best model based on accuracy between multilayer perceptrons predicting `is_happy` based on `pixels`. Compare the following architectures:\n\n - No hidden layers\n - One hidden layer with 10 neurons\n - Two Hidden layers with 10 neurons each\n\nFit both models to `training` and estimate `accuracy` on validation. You don't need to build a Pipeline because the features needed are in the column `pixels`. Pick the best one based on validation performance. The input dimension is 2304 (=48\\*48) and the output is 2"],"metadata":{}},{"cell_type":"code","source":["# model definitions\nmlp = classification.MultilayerPerceptronClassifier(seed=0).\\\n    setStepSize(0.2).\\\n    setMaxIter(200).\\\n    setFeaturesCol('pixels').\\\n    setLabelCol('is_happy').setLayers([48*48, 2])"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# fitting\nmlp1_model = mlp.fit(training)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# evaluations\nmlp1_model.transform(validation).select(fn.expr('avg(float(is_happy=prediction))').alias('accuracy')).show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# model definitions\nmlp = classification.MultilayerPerceptronClassifier(seed=0).\\\n    setStepSize(0.2).\\\n    setMaxIter(200).\\\n    setFeaturesCol('pixels').\\\n    setLabelCol('is_happy').\\\n    setLayers([48*48,10, 2])\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# fitting\nmlp_simple_model = mlp.fit(training)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# evaluations\nmlp_simple_model.transform(validation).select(fn.expr('avg(float(is_happy=prediction))').alias('accuracy')).show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# model definitions\nmlp = classification.MultilayerPerceptronClassifier(seed=0).\\\n    setStepSize(0.2).\\\n    setMaxIter(200).\\\n    setFeaturesCol('pixels').\\\n    setLabelCol('is_happy').\\\n    setLayers([48*48,10,10, 2])\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# fitting\nmlp_simple_model = mlp.fit(training)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# evaluations\nmlp_simple_model.transform(validation).select(fn.expr('avg(float(is_happy=prediction))').alias('accuracy')).show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["BEST MODEL IS ONE WITHOUT ANY LAYERS"],"metadata":{}},{"cell_type":"markdown","source":["**Question 2 (30 pts):** Using the boilerplate code provided below, find four images of people's faces online (the image URLs) one for each of case corresponding to true positive, true negative, false positive, and false negative. Use the best model from Question 1. Remember that we are predicting whether or not someone is smiling, and therefore true positive is \"the model predicts is_happy and the person looks happy\", false negative is \"the model predict is_happy = 0 but the person looks happy\". The images that you find must be fair in that they must be similar to the ones in the training dataset: a frontal face image of people smiling and neutral. The professor provides one true positive URL and one true negative URL as examples"],"metadata":{}},{"cell_type":"code","source":["# BOILER PLATE CODE - DONT MODIFY\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom pyspark.ml.linalg import Vectors\nimport numpy as np\n\ndef get_image(url):\n  # face\n  response = requests.get(url)\n  img = Image.open(BytesIO(response.content))\n  shrinked_img = np.array(img.resize([48, 48]).convert('P'))\n  return shrinked_img\n\ndef display_image(url):\n  plt.figure()\n  plt.imshow(get_image(url), 'gray')\n  display()\n  \ndef predict_image(model, url):\n  new_image = get_image(url).flatten()\n  new_img_df = spark.createDataFrame([[Vectors.dense(new_image)]], ['pixels'])\n  return model.transform(new_img_df)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# POSITIVE\nsmiling_person = 'https://blog.zoom.us/wordpress/wp-content/uploads/2013/09/78813113-1024x682.jpg'\ndisplay_image(smiling_person)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# TRUE POSITIVE \npredict_image(mlp1_model, smiling_person).show()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# NEGATIVE\nneutral_face = \"http://i2.wp.com/detourphotography.ca/wp-content/uploads/2015/11/PPK_0907-Edit.jpg?resize=296%2C446\"\ndisplay_image(neutral_face)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# TRUE NEGATIVE\npredict_image(mlp1_model, neutral_face).show()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Find (e.g., Google Images) URLs for 1 true positive, 1 true negative, 1 false positive, and 1 false negative."],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#True Positive\ntrue_positive = 'https://i.pinimg.com/736x/20/05/48/200548541b488399cd12fcc1bd0c7edb--smile-face-a-smile.jpg'\ndisplay_image(true_positive)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["predict_image(mlp1_model, true_positive).show()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#True Negative\ntrue_negative = 'https://i.ytimg.com/vi/lClsYZebzyw/hqdefault.jpg'\ndisplay_image(true_negative)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["predict_image(mlp1_model, true_negative).show()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#False Positve\nfalse_positive = 'https://assets.lookbookspro.com/atelier-management/gs_5988cb0e-7890-48e1-96f5-34d7ac110004.jpg'\ndisplay_image(false_positive)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["predict_image(mlp1_model, false_positive).show()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["#False Negative\nfalse_negative = 'https://thumbs.dreamstime.com/b/baby-girl-smiling-portrait-little-black-white-square-67277455.jpg'\ndisplay_image(false_negative)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["predict_image(mlp1_model, false_negative).show()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["**Question 3 (30 pts)**: Study neural network architectures to fit the infamous concentric circles dataset. There is boilerplate code to do the data generation, plotting and evaluation. Play with number of hidden layers and with the number of neurons per hidden layer. The input dimension is 2 and the output dimension is 2, but how many hidden layers and hidden neurons are needed to achieve more than 95% accuracy?"],"metadata":{}},{"cell_type":"code","source":["# BOILERPLATE CODE\nfrom sklearn import manifold, datasets\nfrom pyspark.sql import Row\nX, y = datasets.make_circles(n_samples=300, factor=.6, noise=.1, random_state=0)\ndata = spark.createDataFrame(  [Row(x=float(x[0]), y=float(x[1]), label=int(label)) for x, label in zip(X, y)])\n\nplotting_data = spark.range(100).selectExpr(\"(id/100)*3 - 1.5 as x\").\\\n  crossJoin(spark.range(100).selectExpr(\"(id/100)*3 - 1.5 as y\"))\n  \ndef fit_and_plot(estimator):\n  \"\"\"Plot the data and decision surface of estimator\"\"\"\n  va= feature.VectorAssembler(inputCols=['x', 'y'], outputCol='features')\n  df = va.transform(plotting_data)\n  model = estimator.fit(va.transform(data))\n  pp = model.transform(df).select('x', 'y', 'prediction').toPandas()\n  \n  fig, ax = plt.subplots(figsize=(5,5))\n  plt.contourf(pp.x.unique(), pp.y.unique(), pp.prediction.reshape(pp.x.unique().shape[0], pp.x.unique().shape[0]), alpha=0.5)\n  colors=['blue', 'red']\n  for i, grp in data.toPandas().groupby('label'):\n    grp.plot(x='x', y='y', kind='scatter', ax=ax,color=colors[i])  \n  \n  acc = model.transform(va.transform(data)).selectExpr('avg(CAST((label = prediction) AS FLOAT)) AS avg').first().avg\n  plt.title('Accuracy = {}'.format(acc))\n  display()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# this is an example with a logistic regression model\nfit_and_plot(classification.LogisticRegression())"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# try with multilayer perceptron\nfit_and_plot(classification.MultilayerPerceptronClassifier(layers=[2,4,4,2]))"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["# **Extra credit (10 pts) ** \n\n### beat the professor!\nStarting from the following Tensorflow Playground [here](http://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.00001&regularizationRate=0&noise=0&networkShape=4,2&seed=0.00846&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false),\n\nchange any of the following parameters:\n\n- Learning rate\n- Activation\n- Regularization\n- Regularization rate\n- Number of hidden layers\n- Number of neurons per hidden layer\n\nUsually, after you change any of the allowable parameters, you will need to restart the learning by pressing the *reset network* button and then pressing the *play* button.\n\nBut DO NOT CHANGE any of the following:\n\n- Data\n- Ratio of training to test data\n- Noise\n- Batch size\n- Features\n\nReport the parameters you use to achieve less than **0.01 test loss before 20,000 epochs**"],"metadata":{}},{"cell_type":"code","source":["# parameters used to beat the professor: Test Loss = 0.007 before 3000 epochs.\n# - Learning rate: 0.01\n# - Activation: ReLU\n# - Regularization: None\n# - Regularization rate: \n# - Number of hidden layers: 2\n# - Number of neurons in hidden layers: [8,8]"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42}],"metadata":{"name":"homework4-no-key (3)","notebookId":1361444759243770},"nbformat":4,"nbformat_minor":0}
